{"ast":null,"code":"export const blogPosts = [{\n  id: 1,\n  title: \"The DRIVE to Enterprise AI: Architecting the Ecosystem, Not Just the Tools\",\n  excerpt: \"In one of my blogs, I talked about AI aXis, a framework for aligning people, processes, and tools  to create a structured foundation for AI adoption. That premise still holds good and is even more relevant now. Most enterprises are still tinkering with point AI tools, burning their budgets through POCs, and missing the bigger picture - an AI ecosystem that works as one. Because AI isn’t a magic wand.\",\n  content: ` \n    \nReality check (McKinsey Global AI Survey 2024):\n~57 % of companies have adopted AI in at least one function, with $33.9B invested\n≈ $27 B in private-market funding flowed into AI start-ups, just a slice of overall enterprise AI spend\nEarly pilots typically deliver single-digit cost reductions and < 5 % revenue lift\n\nSo where is the gap? Many still treat AI as plug-and-play, when it's really a capability that needs to be architected, embedded, and operationalized across the enterprise.\n\nThe First-Principles Disconnect\nLet's break it down: In one of my posts, I mentioned about thinking from first principles. Truth: AI is a tool, not a strategy; Faulty assumption: merely deploying it will deliver value; Fix: Start with how work actually gets done, and then build layer-by-layer with AI intent. I unpacked some of the first principles, as a foundation base and not optimization layer. \n\nThe WSJ said it best: true ROI shows up when you break the enterprise into atomic tasks. AI isn't about more tools, it's about orchestrating workflows with purpose.\n\nSo, how do CIOs take that atomic thinking and use it to redesign their future proof enterprise AI ecosystem?\n\nThe CIO's Shift: From Control to Enablement\nThe era of central gatekeeping is behind us, no more app builders or system-of-record custodians. Today's CIO or CAO (Chief AI Officer) must shift from tech controller to AI ecosystem creator. That means two fundamental moves:\n\nDemocratize AI, no monopolies, no control towers\nGround strategy in the enterprise, not in vendor roadmaps\n\nCIOs don't need to own every use case. They need empower subject-matter experts and business owners to embed AI into their own workflows. They know where the friction is and where the leverage lies. Enable them with an AI ecosystem to experiment, build, and scale their intent.\n\nThe CIO's role? Build the foundation blocks. Provide the tools. Set the guardrails.\n\nWhat Does a True Enterprise AI Ecosystem Look Like?\nAn enterprise-grade AI strategy can't be a collection of experiments or use cases. It must behave like an operating system for intelligence - layered, coherent, and scalable.\n\nI call it the DRIVE Stack (for easy recall 😊) - five layers that bring together the Infrastructure (Data & Compute), Intelligence (Models & Tools), and Interface (Agents & Experiences). Together, they democratize AI and make it enterprise-grade.\n\nArticle content\nThe D-R-I-V-E to Enterprise AI\nThe D-R-I-V-E Stack breaks down the AI ecosystem into five scalable layers from infrastructure to interface.\n\nArticle content\nD-R-I-V-E Stack\n1. Common Compute Hub – the utility grid\n\nEvery AI workload starts with compute. Enterprises need a shared accelerator backbone (GPUs or ASICs) that teams can access without friction—provisioned instantly, governed invisibly, and tracked in real time, much like spinning up virtual machines (VMs) monitored through FinOps for AI to manage cost. Make compute seamless, and AI experimentation will take off.\n\n2. Curated Data Hub – the raw material\n\nGreat compute is of no use without trusted datasets. CIOs should build an internal data hub like data.gov for the enterprise, where teams can access, preview, and use validated datasets. Ownership, versioning, and quality checks turn data into building blocks—and minimize hallucination, bias, or drift.\n\n3. Foundation Model Engine – the intelligence layer\n\nPre‑trained LLMs / SLMs and vision models—fine‑tuned on enterprise and industry context—should be productized behind secure endpoints. Offer both horizontal models (general reasoning, code, images) and vertical packs (claims adjudication, demand forecasting, employee policy). Provide simple configuration controls and clear performance metrics so teams can optimize without reinventing the wheel.\n\n4. Tooling Workbench – the enterprise workbench\n\nIf foundation models are the brains, the Tooling Workbench is the muscle that turns insight into outcomes. This layer equips business teams with a suite of tools—no heavy coding needed—to stitch AI into day-to-day workflows.\n\nIt includes pre-built connectors to core systems like ERP, CRM, and HR platforms.\nWorkflow engines automate routine tasks—think approvals, escalations, and validations.\nSecure data bridges let insights from AI models flow directly into the applications where decisions are made.\n\nThis enables teams to assemble solutions—not code them from scratch. Whether it's building a seamless customer onboarding journey or generating marketing campaigns on demand, teams can mix and match blocks to create end-to-end flows. Every step is traceable, governed, and auditable—so innovation doesn't come at the cost of control.\n\n5. Agent Marketplace – the end-user experience\n\nAt the top: AI agents that work like apps. Sales copilots, procurement bots, support responders—each powered by the stack beneath. And when business needs something new? They can compose their own using reusable through DRIVE building blocks—often with central validation in sensitive domains like banking and healthcare.\n\nApplication mindset: Together, these layers don't just power AI workflows—they enable a new generation of AI-native apps, composed from building blocks rather than coded from scratch. modern apps = agents + workflows\n\nWhen these five layers lock in, AI stops being a POC lab project. It becomes a repeatable platform that scales across the business. Early adopters like Walmart and DBS Bank are already proving what's possible when you go all in. \n\nFrom Hype to Highways: Rethinking the CIO's Role\nCIOs have spent years fighting tool sprawl. The game has changed now. It's no longer about provisioning another SaaS license—it's about engineering an enterprise-wide intelligence grid.\n\nPicture D-R-I-V-E as a national highway system for insight:\n\nCommon Compute Hub is the asphalt—smooth lanes so every team can move without bottlenecks\nData Hub + Intelligence Engine are the vehicles and fuel—moving insight to where it's needed\nTooling Workbench is the interchange—on-ramps, exits, and merges for insight to flow into work\nGuardrails are the traffic laws—speed limits and checks to ensure safety and trust\nAgent Marketplace is the commerce zone—plug-and-play copilots or custom AI agents on demand. They're the commerce that alongside highways—readymade stops for teams to pull over and use, or small custom shops that for special needs.\n\nThe AI Superhighway doesn't deliver value just by existing. It delivers when the business builds on top—faster decisions, smarter workflows, and new digital products.\n\nMandate for the Modern Day CIO\nForget chasing the next flashy tool. The real mandate is to architect the AI ecosystem, guided by the AI aXis to align people, processes, and tools, and powered by the DRIVE Stack to operationalize intelligence at scale.\n\nBuild, maintain, and keep widening the AI Superhighway so every function - sales, finance, supply chain, HR—can experiment, build, and scale with confidence.\n\nBecause AI isn't a point upgrade. It's the infrastructure of the future—and the AI ecosystem you lay down today will decide how fast and far the business can go tomorrow.`,\n  date: \"2025-13-06\",\n  tags: [\"EnterpriseAI\", \"DRIVEStack\", \"AIStrategy\", \"TechLeadership\"],\n  readTime: \"5 min read\"\n}, {\n  id: 2,\n  title: \"The AI aXis: Realizing the Full Potential of Generative AI with agentX\",\n  excerpt: \"As artificial intelligence (AI) continues to reshape industries, businesses are at a critical juncture. Yet, realizing its full potential requires more than just implementing AI—it demands a strategic ecosystem that aligns people, processes, and tools.\",\n  content: ` As artificial intelligence (AI) continues to reshape industries, businesses are at a critical juncture. Yet, realizing its full potential requires more than just implementing AI—it demands a strategic ecosystem that aligns people, processes, and tools. In my previous post, I highlighted the promise of Tech Mahindra's agentX, which enhances user productivity by automating repetitive tasks and achieving productivity gains of up to 70% (AI Magazine, 2024). Today, we will take a closer look at how businesses can harness the promise of agentX by exploring the necessary ecosystem for its success.\n\nGenerative AI (GenAI) is more than a tool or a technology; instead, it is a transformative force that could revolutionize industries and unlock untapped opportunities. However, the true power of GenAI lies not in the technology itself but in the broader ecosystem, supported by three critical levers: people, processes, and tools. Together, these elements form the AI aXis.\n\nBefore we explore the components of the AI aXis, let's consider an analogy. Imagine you purchased a Ferrari, a car that promises to accelerate from 0 to 60 mph in under five seconds. Exciting, right? But what happens if the driver is only trained to drive a Fiat, and the road is riddled with potholes? Can Ferrari still deliver on its promise? Likely not. GenAI is your Ferrari—a powerful tool with extraordinary potential. But to unlock its capabilities, you need to focus on the three critical elements of the AI aXis: the driver (people), the road (processes), and the engine (tools). Each of these elements is indispensable. Without skilled drivers, smooth roads, and a powerful engine, even a Ferrari won't perform. The same holds true for GenAI—its success relies on aligning people, processes, and tools to achieve seamless integration and transformative outcomes. This is where agentX, Tech Mahindra's GenAI-powered suite, steps in as a key enabler of the AI aXis. \n\nThe Role of An AI Blueprint: The Foundation of Transformation\nBefore embarking on their GenAI journey, organizations need a clear AI blueprint—a comprehensive roadmap that guides every step of the transformation. This blueprint helps to ensure that all AI initiatives are aligned and working toward the same strategic objectives. Without a robust AI blueprint, organizations risk fragmented efforts, where isolated AI projects lack the cohesion to deliver meaningful results.\n\nAn AI blueprint is not static; it should evolve over time and must be updated regularly to reflect changing business priorities. It defines the organization's AI strategy, focus areas, and alignment with long-term goals. It also lays the foundation for how people, processes, and tools will work together to create a cohesive and efficient AI aXis. Many organizations experiment with isolated AI tools or implement solutions without a proper blueprint, which can lead to a lack of meaningful and sustainable outcomes.\n\nPeople: The Driver of the AI aXis\nNo matter how advanced the technology is, its potential remains untapped without a workforce that can use it effectively. People are the drivers of GenAI and must be equipped with the skills, mindset, and confidence to work alongside AI systems effectively.\n\nLeadership is crucial in driving this transformation. By prioritizing upskilling and reskilling, businesses can ensure their workforce is equipped to engage with AI tools, interpret insights, and collaborate seamlessly with these systems. Beyond technical training, there needs to be a cultural shift where employees view AI as a valuable enabler. A well-trained and confident workforce is the cornerstone of the AI aXis, ensuring that GenAI delivers its full potential.\n\nBusiness Processes: Paving the Road for Transformation\nMany organizations make the mistake of embedding AI into existing workflows without reimagining them. This strategy is similar to patching potholes instead of building a new road.\n\nTo fully unlock AI's potential, business processes must be redesigned from the ground up to align with AI capabilities and organizational goals. Additionally, these business processes must be agile enough to adapt to the rapid evolution of AI technologies. Establishing cross-functional workflows is necessary to eliminate silos and enable seamless collaboration. Organizations must reimagine business processes and embrace agility to drive efficiency and innovation at scale. \n\nTools: Building the AI Engine\nLegacy tools, built for pre-AI environments, often need more scalability and flexibility to meet today's demands. This is where 'AI-first tools' come in. These are tools specifically designed for AI environments, with features that enable scalability, adaptability, and seamless integration. To unlock the full potential of GenAI, organizations must invest in these tools. Think of these tools as the engine of the Ferrari. Without a powerful, purpose-built engine, even the smoothest road and the most skilled driver will struggle to deliver results. AI-first tools provide the foundation for automating processes, extracting insights, and scaling innovation across the enterprise. While the AI aXis framework—comprising people, processes, and tools—is essential for GenAI's success, organizations must address foundational challenges to unlock its full potential. These include ensuring data readiness, as high-quality, well-governed data is vital for AI systems. It also involves addressing ethical concerns such as bias, transparency, and privacy, alongside managing resistance to change through effective adoption strategies. Acknowledging and addressing these challenges is key to creating a sustainable AI ecosystem that delivers meaningful results.\n\nAligning the AI aXis with agentX\nWhen the three elements of the AI aXis—people, processes, and tools—are aligned, the full potential of GenAI can be realized. They transform GenAI from merely a high-performance vehicle on a rough road with an untrained driver into a powerful machine that achieves outstanding results. People provide the creativity and competence to engage with AI effectively. Processes create the structure and efficiency to maximize AI's impact. Tools deliver the power and scalability to turn vision into results. Together, these elements form a unified AI aXis that drives success.\n\nThis is where agentX plays a pivotal role. As a GenAI-powered suite, agentX is designed to align the AI aXis and address the challenges organizations face. It transforms how people, processes, and tools work together, providing the foundational AI blueprint and enabling seamless adoption of GenAI. For example, agentX can automate patient scheduling, allowing medical staff to focus on patient care. In the finance sector, it can automate routine data analysis tasks, freeing up analysts to focus on strategic decision-making. For manufacturing, it can optimize supply chain management, reducing costs and improving efficiency. These examples illustrate how agentX can be customized to meet the specific needs of various industries.\n\nagentX also offers a robust 'AI starter pack for organizations.' This pack includes a foundational AI blueprint that guides organizations through every step of their AI transformation and strong organizational change management practices that help businesses effectively drive transformation, navigate challenges, and deliver sustainable outcomes. It's like having a comprehensive guide and a support system to ensure your AI journey is successful.\n\nRealizing the Full Potential of GenAI\nOrganizations must take a proactive and integrated approach to unlock GenAI's promise. Businesses can create a sustainable AI ecosystem by developing a clear AI blueprint, aligning AI aXis, and addressing challenges like data readiness and ethical considerations. Solutions like agentX provide the tools and strategies to bridge gaps, empower teams, and reimagine workflows.\n\nGenAI's potential lies not just in the technology itself but in its surrounding ecosystem. With agentX, organizations have the ultimate toolkit to deliver on GenAI's promise and drive unprecedented outcomes. It's not only about having a high-performance vehicle—it's also about training the driver, paving the road, and building the engine. With agentX, the journey to transformation becomes seamless, impactful, and future-ready.`,\n  date: \"2025-01-06\",\n  tags: [\"AgentX\", \"EnterpriseAutomation\", \"AITransformation\", \"TechMahindra\"],\n  readTime: \"6 min read\"\n}, {\n  id: 3,\n  title: \"Next-Gen BSS for Digital Economy\",\n  excerpt: \"BSS is an integral part of any CSP to handle product, order, revenue, and customer management.\",\n  content: `\n    BSS is an integral part of any CSP to handle product, order, revenue, and customer management. With ~2% of the total spend, many CSPs view BSS as a cost center with a perpetual push to drive down the cost. Historically, CSPs have been through the cycles of buying “Best of the Breed” solutions put together by SI’s to buying out of the box “Best of the Suite” offering end-to-end solutions. But neither come close to meet CSP’s requirements in a nimble, agile, cost-effective manner with vendor neutrality. These transformation projects have a high cost overrun; hence CSP’s hesitation in undertaking these projects does not surprise, thereby letting them continue with highly customized and hard to retire legacy systems. On the other hand, with flat BSS spend (in line with CSP revenues), key suppliers are reconsidering their commitment as they do not consider BSS as an attractive market.   \n\nWhile CSP’s struggle with the BSS technology debt, modern-day players like Netflix use simple pricing models and systems to support their business. The CSP’s may view BSS as an overhead, but new-age players like Netflix have invested in customer experience, personalization, and building data-led BSS systems that anticipate the kind of service customers would want, thereby allowing them to cross-sell / up-sell. CSP’s are attempting to transition to next-gen BSS at par with Netflix’s world but are struggling to do so. They have limited experience building a modular, configurable architecture that reduces the need for customization and support. Notwithstanding the dilemma, there is a realization amongst CSPs that next-gen BSS can expedite their growth through better customer experience and loyalty.  \n\nLooking at some of the critical aspects, next-gen BSS systems would need to have a cloud-native architecture (built ground up to work on cloud as against being cloud-ready or lift & shift) providing scale and flexibility required to support the modular requirements of CSP’s, minimal levels of customization and seamless integration with other ecosystem partners offering SAAS. The on-demand delivery model changes CSP’s commercial terms to business outcomes rather than getting billed for HW & SW. With increased digitization, next-gen BSS would need to go beyond the core services of voice, data, etc., and seamlessly support cross sectors loyalty schemes like loans, credit cards, etc., in summary offering the whole lifestyle experience. Building a solid Partner ecosystem is an essential capability of next-gen BSS as it will enable CSPs to thrive and succeed in the new age digital economy. Partners across the industry must engage with CSPs that offer them the flexibility to verticalize the CSP services along with partner IP. This model has been successfully emulated by Hyperscaler’s, allowing partners to build solutions, effectively letting them cobrand their solutions, define their pricing, hold direct customer relationships with the ability to co-sell and resell. Partners can utilize the underlying marketing, billing platform and divide the revenue/earn incentives. Next-gen BSS would need to support new forms of payments, i.e., customers should be able to transact and pay for services beyond EFT/credit cards like Apple Pay, Venmo, Loyalty points, Bitcoins. Another essential aspect would next-gen BSS is to support dynamic pricing, promotions & bundling of services for greater customer satisfaction, loyalty, and revenues. Spikes in usage often lead to service degradation and eventually customer dissatisfaction. Rather than constraining customers for the bandwidth, they signed up for, liquid Infrastructure based BSS networks can behave intelligently, allowing dynamic changes to the bandwidth (Bandwidth on Demand).  \n\nSome of these characteristics will provide CSP’s agility and flexibility to serve their customers and scale the business. It is time for CSPs to move from a static, labor-intensive legacy BSS system to a next-gen BSS system that intelligently adapts to meet the growing digital demands of their customers built on the ethos of ‘Customer Experience Loyalty.’ `,\n  date: \"2021-05-12\",\n  tags: [\"CIOLeadership\", \"AIEcosystem\", \"DigitalTransformation\", \"TechStrategy\"],\n  readTime: \"3 min read\"\n}, {\n  id: 4,\n  title: \"Putting together the Ecosystem for Open RAN\",\n  excerpt: \"There are many choices for the operators to pick from the array of solutions needed to build the network. However, in the absence of a single solution provider, the key hurdle they face is blending these components seamlessly, including making them deployment-ready with 'single throat to choke.'\",\n  content: `\nIn the previous write-up, we discussed how system integrators (SI's) are best placed to stitch SW-driven RAN through the ecosystem of partners ranging from radio components to HW partners required for CU, DU, RU to SW providers. This opens many choices for the operators to pick from the array of solutions needed to build the network. However, in the absence of a single solution provider, the key hurdle they face is blending these components seamlessly, including making them deployment-ready with 'single throat to choke.'\n\nOpen RAN Partner Ecosystem\nSI's may be best suited to stitch the RAN components and bring the ecosystem together. However, this job has a high degree of complexity, demands advanced skills and knowledge.\n\nThe article 'Who disaggregated my RAN' details some critical areas that need attention to integrate these components from multiple vendors and make them deployment ready. These include\n\nIntegration demands knowledge of underlying hardware and software environments, industry standards (3GPP, O-RAN, Small Cell Forum, etc.), system architectures, hardware processors, System-on-Chip platforms, etc.\nTesting the network functions and ensuring their collective working requires knowledge of industry-standard tools, automating multiple levels of testing across multi-vendor components for the systems to meet the QoS levels defined by the operator.\nBenchmarking to ensure that RAN solutions perform at par with traditional systems for data rates, latency, and other performance aspects.\nDeployment Readiness for an integrated solution to meet the industry-standard benchmarks and operator-specific norms like operator-specific tests, regulatory compliance for various countries, etc.\nFor the greenfield implementations, these are just some of the capabilities required to put the SW-driven RAN together. While the promise around cost savings and vendor lock-in of the SW-driven RAN / Open RAN may be massive, but they can be surpassed by the potential downsides. Trials are in the early stages and still far away from the carrier-grade scalability that offers reliability, higher workloads, and performance. It is still to be seen how the savings will play out as the operators start integrating SW-driven RAN with the legacy RAN (a whole new paradigm of complexity), which to date have mostly been closed and propriety implementations.\n\nSI's will need to embrace these challenges, as this is one area that they cannot afford to ignore or underinvest. To draw parallels, we have seen the shifts in the IT infrastructure side to Hyper-converged infrastructure, which offers software-defined IT infrastructure virtualizing all the elements of conventional \"hardware-defined\" systems. Similarly, SDN has centralized intelligence and routing through the software layer and virtualizes the underlying hardware. The shift to SW-driven RAN is a foregone conclusion, though it will be some time before it gets industrialized. Even though we may see few years of disillusionment with mixed results, SW-driven RAN will mimic the broader industry transition pattern. It is expected that more than 80% of core wireless network deployments will be virtualized.\n\nAnd it is not the greenfield implementations that SI needs to focus on; the co-existence of SW-driven RAN with legacy RAN is critical given significant investments from the operators. This is another area where SI will need to invest in building capabilities (both organically and inorganically ) that addresses interoperability issues, which means they need to learn the know-how of legacy RAN, not a bright spot for many SI's as the legacy RAN market has been dominated by traditional Telco OEM's. While SI' may have an advantage as the RAN gets more and more software'ized and cloud'ified, it also increases the multiple combinations of HW and SW that need to undergo extensive testing before being put to production. SI's are still in the early stages of building the capability around open RAN, while it may be challenging but not difficult. Perhaps we can draw parallels to how SI's navigated the cloud shift and build their capabilities over the past two decades.\n\nKeen to hear your views around how the journey will play out for SI's and if they will be able to create space for themselves when we are seeing the emergence of new-age SW driven Telco OEMs and willingness from traditional Telco OEMs ' to shift their business model from bundling proprietary HW's & SW's to virtualized SW deployed on the public and private cloud.`,\n  date: \"2021-03-29\",\n  tags: [\"ProductAI\", \"AIIntegration\", \"EnterpriseAI\", \"TechMahindra\"],\n  readTime: \"3 min read\"\n}, {\n  id: 5,\n  title: \"RAN Integration - SI's vs. Telco OEM’s\",\n  excerpt: \"With multiple players coming to play in the Open RAN framework across hardware, software, data center segments, there is a genuine concern building up with the MNO’s around who has the ownership of putting this entire puzzle together with the bottom line on performance reliability while keeping the cost down.\",\n  content: `With multiple players coming to play in the Open RAN framework across hardware, software, data center segments, there is a genuine concern building up with the MNO’s around who has the ownership of putting this entire puzzle together with the bottom line on performance reliability while keeping the cost down. Several models are under exploration where MNO (ex. Vodafone and Rakuten) with in house capabilities and skills have played the SI role in stitching up the entire stack together for their pilot projects, while in other cases, the hardware provider is playing the SI role (Dish expects Fujitsu to provide support for radio and antenna integration)      \n\nIt will be hard for a hardware vendor or a 100-year-old MNO to invest and build these capabilities. With more RAN components getting developed and delivered through cloud-native containerized service, there is an increasing possibility of offering RAN-as-service on the near horizon. These new hybrid cloud-based deployment models would need software-centric capabilities and approaches, which a typical MNO or a hardware vendor would find hard to bring in. Integration of Open RAN for a software-centric world would mean software connecting with to all physical components, at all times, to deliver scalability, innovation which changes the game for how open networks integrate. Integration principles typically applied to traditional RAN cannot be applied to a software-driven one where the SW upgrades will happen over the air rather than tower climb up or through truck rolls.     \n\nSI’s are increasingly becoming active and forging partnerships with the likes of Altiostar, Parallel Wireless to build open RAN blueprints that network providers could use to accelerate the deployment of 4G/ 5G Open RAN solutions on their network. WTT, in partnership with CISCO and Altiostar, is building a blueprint where Cisco will provide its Virtual Infrastructure Manager (CVIM) platform, Ultra Packet Core, and Converged SDN Transport along with Altiostar’s 4G and 5G open RAN software. WTT, along with Alitostar and Cisco, will take this validated blueprint and the fully integrated and tested solution to network operators, which in turn will help them to accelerate the technology decisions, reduce time to market, test and deploy the prebuilt validated Open RAN architecture-based solutions in their network, which otherwise could them up to a year to do design, test and validate. Another leading SI recently was signed up by Three UK, one of the UK's leading mobile network carriers, to help the latter configure its mobile network for its ongoing rollout of 5G services. Some of the SI’s are also building the ‘Next Generation Factory Model’ where the facilities offer on-demand labs, conduct proof of concepts, product comparison capable of supporting design, development, and testing for the complex multi-vendor solutions.    \n\nTraditional Telco OEM players like Nokia, Ericsson who have played across HW and SW (though proprietary), may not work well in the Open RAN environment. SI’s are better positioned to offer impartial and not aligned or associated with a specific hardware or software vendor. They are also integrating and testing the Open RAN SW and COTS HW; in many cases, they use the same set of tools for DevOps, CI/CD, and Automation as used in the web app world considered as a sweet spot of the SI’s. For example, in Peru, Telefónica has relied on a Spanish systems integrator called Everis, building in-house resources for implementing virtualization based on Whitestack for DevOps style with Continuous Development Continuous Integration of the software to enable automation. But that’s where the advantage SI ends; Open RAN implementations are still in the early stages with several pilots underway. Nokia recently announced a partnership with hyperscalers, pairing its radio access network (RAN) technologies for 5G and cloud services from Microsoft Azure, Amazon Web Services (AWS), and Google Cloud. The old horses are now focusing on virtualizing their scale-tested network functions on the cloud, which can be deployed in a distributed manner from centralized to the distributed cloud. Open RAN still has some way to go before it gets into mainstream adoption by the MNO’s for the scale operations, where SI’s could play a dominant role. Telco OEMs' willingness to shift their business model from bundling proprietary HW’s & SW’s to virtualized SW deployed on the public and private cloud gives them an edge and deliver to some of the Open RAN's promises like containing the costs for MNO’s. Keen to hear your thoughts on how Telco OEMs will evolve in the new emerging environment of RAN softwareization and how SI’s will create a market for themselves.   `,\n  date: \"2025-01-24\",\n  tags: [\"StartupAI\", \"EnterpriseSaaS\", \"ProductLeadership\", \"TechFounders\"],\n  readTime: \"4 min read\"\n}, {\n  id: 6,\n  title: \"'Mobile core as-a-service'​ powered by Hyperscalers\",\n  excerpt: \" While the interest is unprecedented, some questions are lingering around technology roadmap and maturity to realize ROI on private 5G networks and the best way to put private 5G networks on their implementation roadmap.\",\n  content: `Earlier, we discussed interest from the enterprises, especially the manufacturing companies, in deploying private 5G networks. While the interest is unprecedented, some questions are lingering around technology roadmap and maturity to realize ROI on private 5G networks and the best way to put private 5G networks on their implementation roadmap.\n\nThe last few months have seen an action-packed set of events, where wireless software companies from 'leaders' to 'challengers' made news with hyperscalers. New players like Affirmed Network, Metaswitch got acquired by Microsoft, Nokia - Google announced a partnership to develop cloud-native 5G Core. At the same time, Cisco, Altiostar partnered to create blueprints to accelerate 4G/5G deployment. Operators, too, for quite some time have been toying with hyperscalers where Vodafone & Verizon partnered with AWS to explore edge computing opportunities. The industry's unprecedented action is not surprising given the move to 5G commercialization and private networks. While operators are making the bulk of the investments in building the 5G infrastructure, hyperscalers and wireless software companies are deepening their relationship to run the complex network functions on the hybrid cloud to support a variety of 5G business use cases. \n\n5G fundamentally has different business characteristics from all its predecessors (2G/3G/4G). Previous versions of G's are meant for basic services like Voice / Data / SMS leading to under/over utilization of network resources. For Example, both SMS and end-user playing a game requiring real-time interaction would have access to an equal amount of network resources leading to inefficient utilization of resources for the operators. 5G, with its software-driven approach, gives the ability to design, develop and host 'mobile core' for each type of user/traffic type. For Example, a core could be designed and separated to support messaging (Less bandwidth), or for IoT traffic (secured and streaming), Smart cars, AR / VR (Real-time and high-speed network), etc.\n\nOperators and businesses (for private 5G) require a 'mobile core' that can be deployed and seamlessly managed on the hybrid cloud; support carrier-grade network functions powered by AI, network slicing, etc. - all built with compliance & security first as the underlying principle. With a software-driven approach for 5G, wireless software providers have made extensive use of automation and modern software development principles (DevOps / CICD / Agile lifecycle development). On the other side, Hyperscalers offering compute, storage, analytics, databases, network, machine learning, and several other on-demand services can easily extend their network services to include 5G services like 'mobile core' deployed on hybrid cloud, layered with intelligence, analytics & machine learning. 'Hyperscalers' along with 'wireless software providers' allows businesses to build their private networks in an OPEX model, as it does not necessitate them to procure hardware to host 'mobile core.' With CAPEX out of the window, businesses can now get the fully packaged managed services from 'deployment to operations' for their private networks.\n\n'Mobile core as-a-service' from hyperscalers would offer benefits like fully automated deployments (faster, safer, repeatable), ease of management and orchestration of workloads on hybrid cloud, giving deployment flexibility, automated scaling of network functions for demand-driven network growth, automated fault detection, and correction - reducing manual monitoring and reduced operational complexity. For operators, the additional benefits would include doing away in managing and running the data centers.\n\nPrivate 5G networks for business are an easy target for hyperscalers to offer 'Mobile core as-a-service,' as it allows them to lower the TCO without the hassle of owning up the infrastructure. The question remains, how much operators will adapt and move their core network functions and compute workloads on the cloud. After all, there is a bitter feeling coming out of the 4G era where operators spent billions building the network but lost on monetization to OTT players. While the softwareization of 5G has pushed operators to co-exist with hyperscalers making them frenemies, I am keen to hear your thoughts if operators would eventually adopt services like 'Mobile core as-a-service' from hyperscalers and scale it up for complex 5G use cases.  \n`,\n  date: \"2021-02-16\",\n  tags: [\"CoPilot\", \"GenerativeAI\", \"Innovation\", \"MicrosoftPartner\"],\n  readTime: \"3 min read\"\n}, {\n  id: 7,\n  title: \"Is Private 5G on your Roadmap?\",\n  excerpt: \"We all have been hearing about 5G for some time and its benefits over LTE / Wi-Fi. 5G offers higher reliability, high speed, low latency, making it most suitable for industrial IOT scenarios.\",\n  content: `We all have been hearing about 5G for some time and its benefits over LTE / Wi-Fi. 5G offers higher reliability, high speed, low latency, making it most suitable for industrial IOT scenarios. The excitement over private 5G is understandable, but this is not something new as private LTE networks have been in existence for some time, mostly offered by operators. With 5G, enterprises now have access to unlicensed spectrum (ex. CBRS), allowing them to build a private high-speed network with more bandwidth than the 4G / LTE offered operators. So, it does not surprise us when we see increased interest in private 5G networks from Ford Motors, BMW, BASF, Corning, etc. Off late, the German industrial companies have taken the lead and applied in dozens for licenses to operate their own 5G networks.\n\nIt is not just the manufacturing companies; the spike in interest for private 5G networks is across the industry. To work efficiently, industrial IoT, smart cities, campus networks, modern healthcare, smart manufacturing, intelligent facilities, logistics, and several others need to automate and make sense of their surroundings through robots, intelligent sensors, etc., A low latency network like 5G allows them to remain interconnected and communicate with other devices, enabling them for real-time decisions. While there is a broad consensus on the need and benefits of private networks, the dilemma organizations often face working with traditional operators who know how to design, build, monitor & manage the network vs building their own private 5G network along with a handful of chosen partners (Across OEM's, SW providers etc.).\n\nThanks to the softwarization of networks, cloud, and IoT, we have seen the emergence of new players who have built capabilities in designing, building, and operating private networks. Traditionally, the hardware and software needed to connect the cell sites and run 5G networks come from Huawei, Erickson, Nokia, etc. These proprietary and purpose-built hardware do not offer any decoupling with the software. In Feb 2019, Facebook open sourced Magma, a software platform that helps operators deploy mobile networks quickly and easily, offering software-centric mobile packet core and tools to automate the network management and deployment. Since then, many companies like FreedomFI provide their version of the open-source Magma to the customers, which can be run-on general-purpose hardware. With the software that can run-on general-purpose hardware and spectrum available (outside the control of network operators), enterprises can build their private high-speed network at a significantly lower cost. With private 5G networks, the organization owns the wireless spectrum for the network, network base stations, and other infrastructure. This provides them full control over the network while strengthening cybersecurity, isolating users from the operator's network, and several other benefits.\n\n5g is impacting the present and only going to accelerate its adoption within the organizations. Some may think that this implementation will leave a hole in the enterprise pocket, but that not the case. By some estimates, the private 5G networks can reduce the infrastructure TCO by up to 75%. One such example is where the automated process of crane lifting a container from a remote center gave 70% savings in labor cost at the shipping port.\n\nWhile the benefits of the private 5G networks are unprecedented, there are some questions organizations have in their mind - 1) Given the ongoing softwarization of networks, has technology matured for them to realize ROI on private 5G networks 2) What's the best way to put private 5G networks on implementation roadmap (engage with traditional operator's vs. with the new age partners or any other model).\n\nLet me know your thoughts or if you would like a discussion to demystify this further.`,\n  date: \"2021-01-21\",\n  tags: [\"BSS\", \"Telecom\", \"DigitalTransformation\", \"CloudNative\"],\n  readTime: \"3 min read\"\n}, {\n  id: 8,\n  title: \"Maximizing ROI with agentX: The Final Dimension\",\n  excerpt: \"In the previous blogs, we have delved into two aspects of the agentX Triple Advantage — peeling the layers that make TechM agentX transformative and what lies beneath the surface.\",\n  content: `In the previous blogs, we have delved into two aspects of the agentX \"Triple Advantage\" — peeling the layers that make TechM agentX transformative and what lies beneath the surface.\n\nFirst, in \"The AI aXis,\" we discussed how agentX brings forth the ecosystem necessary for enterprises to embrace Gen AI, which could potentially help increase productivity by upwards of 70%.\nSecond, agentX enables operational efficiency in the enterprise ecosystem by simplifying workflows and discarding unnecessary layers of complexity.\n\nThird and most importantly, agentX enables enterprises to achieve maximum ROI from AI investments. By leveraging existing investments and assets to uncover untapped opportunities and scale operations, agentX delivers real value and brings enterprises closer to the breakthrough results they've been chasing. In this post, we'll examine how agentX fulfills the last piece of its \"Triple Advantage” and why this dimension may be the missing link in your enterprise AI strategy, a vital step towards becoming an AI-first organization.\n\nThe Challenge of AI Sprawl\nThere are already many AI tools in the market clamoring for attention. Each targets a particular role or task, be it content creation, design, development, or knowledge work. While these tools boost individual productivity, the bigger question remains: How do we combine all these AI tools to elevate enterprise-wide productivity?\n\nAdding another wave of AI tools on top of the many enterprise applications that CIOs are already fighting is daunting, especially when security, compliance, and compatibility issues are factored in. While the workforce is eager to explore the latest AI tools, this constant influx only complicates compatibility, security, and compliance issues. It's common for users to cobble together several tools to accomplish a single task; for instance, they might use something like Copilot for brainstorming and generating content and Napkin AI for images, switching back and forth between various tools to get a job done (note: no endorsement implied here).\n\nSecondly, companies have already made significant investments in automation. New AI capabilities must build on these existing foundations rather than duplicating prior investments.\n\nagentX as the AI Orchestrator\nEnter agentX, The AI Orchestrator. At first glance, this may sound like one more addition to an already bustling AI landscape of tools. agentX is more than just another AI tool; it brings the whole AI ecosystem under one roof as an \"AI Orchestrator.\" By leveraging existing AI and automation investments, adding intelligent agent capabilities ensures that agentX allows businesses to stitch together disparate AI tools and existing automation into an integrated environment. That's where agentX brings in its AI, Agents, and Automation- another \"Triple Advantage.\"\n\nLet’s understand how agentX combines these to make an AI-first enterprise.\n\nBeyond the Hype – The Road to Practical AI Agents in the Enterprise\nAgents are a hot topic. Your LinkedIn feed is likely filled with posts, discussions, and articles about the rise of autonomous agents—or even an \"army of agents\" on its way as if humans didn't already provide enough competition.\n\nThere's no denying the excitement about AI agents' prospects, but we're still early in the hype cycle. Like any other technology, we'll probably progress from initial excitement to inevitable disillusionment before finally settling into a practical, real-world understanding of what agents can and cannot do. While there's little doubt that agents are coming, the question is whether they're ready to disrupt the enterprise landscape. Let's look at how agents might mature and finally deliver on their promise of autonomy.\n\nThe Journey of GenAI Agents: From Interns to Autonomous Experts\nGenAI-based agents will usher in a new wave of automation in enterprises. This may be controversial and purely a representation of my thoughts, but the journey toward fully autonomous agents will also gradually progress, much like the professional growth that happens with human employees, from intern to expert.\n\nFollowing are four essential maturity levels of GenAI agents, each offering different benefits in the aspect of Autonomy, Efficiency, Adaptability, and Scalability:\n\nArticle content\nEmbracing a Continuous Journey with Agents\nOne thing to remember is that the maturity of an agent is not a \"Day 1\" thing-it's a continuous learning journey that will keep evolving with data, workflows, and tools. Beyond the hype cycle, we will get a better view of how fully autonomous agents, augmented by human oversight, could take a more goal-oriented approach in their actions, further presenting themselves as digital twins of humans powered by LLMs with memory for adaptation and learning in real-time and can be certified with confidence by CIOs to operate with enterprise-grade. That doesn't mean, however, that organizations should stand on the sidelines. The maturity timeline may be extended, especially in training agents to handle edge cases, but now is the time to start experimenting. Find the right use cases early and ramp up agent maturity from intern to autonomous to set a strong foundation for future success that one might call \"Forward Failure.\"\n\nAutomation: The Steppingstone to Cognitive Agents\nWith agents in the spotlight, it's easy to overlook another essential part: automation. At the same time, it may seem like a less glamorous, over-discussed topic, but automation remains central to truly unlocking AI's potential within the enterprise. Let's look at how automation pairs with agents to create a seamless, intelligent workflow—and why you might want to use this \"less glamorous\" automation along with agents to build an AI-first enterprise.\n\nEnterprises have spent significant time, effort, and money on automation in the last couple of decades. Is that all suddenly becoming obsolete because AI agents are showing up? Probably not, at least not for now. Instead, LLMs will enable organizations to take incremental steps on top of the existing automation, inject cognitive capabilities into the workflows, and train the next-generation agents.\n\nAutomation will, in many ways, coexist with agents in the near to middle term, enabling businesses to capitalize on their current systems and substantial investments already made. The probabilistic nature of AI means that trusting agents to deliver perfect results 100% of the time isn't feasible, at least not right away. As these agents mature from \"intern\" status to \"autonomous experts,\" automation will remain the backbone that ensures critical tasks are executed reliably. Over time, we may see automation and agents powered by LLMs converge into a single, fluid ecosystem, but that's still a few stages away from maturity. Until then, a coexistence model lets enterprises embrace AI-driven innovation at a measured pace, preserving business continuity while confidently experimenting with the future of autonomous agents.\n\nAI: The UI Layer of \"Triple Advantage\"\nHaving discussed agents and automation, let's move on to the final layer: the AI layer- or, as we might call it, AI for every UI. Whether text, image, voice, or video, enterprises need to connect a range of AI tools to deliver end-to-end user experiences and business solutions. I discussed this in detail in my previous blog, \"No Clicks, Confusion, Just Conversation.\"\n\nFor instance, consider End-to-End Automation of the SDLC—from requirements gathering to code development, testing, and deployment. Here's how integrating AI tools can streamline the process: GitHub Copilot is the engine at the core, enhancing code quality and performance. It plugs seamlessly into popular tools like VSCode, Jira, and DevOps, creating a cohesive development environment. The approach maximizes ROI by leveraging existing investment in productivity tools with a unified solution, enabling better asset utilization and efficiency.\n\nIn the future, these AI-driven interfaces may blend even more closely with agents—but for now, it's all about the coexistence of AI, Agents, and Automation.\n\nagentX: The Orchestrator & Integrator\nagentX from TechM puts all these together: AI, Agents, and Automation into one cohesive ecosystem. agentX is an \"AI Orchestrator,\" ensuring enterprises leverage existing investments while embracing new AI breakthroughs. Further, this step-by-step modernization aligns the maturity of agents with human oversight and operational workflows.\n\nIt's a transformative approach that merges automation with intelligent decision-making. While traditional automation handles predefined tasks, agentic AI can learn, reason, and adapt in real time, offering greater flexibility. In the long run, this synergy moves organizations closer to a future of truly autonomous operations.\n\nFinal Thoughts\nStay Pragmatic. We're still early in the agent hype cycle, so careful oversight and practical use cases are key.\nBuild on What You Have: Enhance existing AI and automation tools with cognitive and agent-based capabilities rather than replacing them.\nAdopt Gradually: Embrace a \"Forward Failure\" mindset—experiment, learn, and refine.\nLeverage agentX: If you're seeking a solution that orchestrates your entire AI ecosystem, TechM agentX is designed to help unlock the potential of AI, Agents, and Automation together.\n\nTechM agentX enables organizations to maximize ROI by uniting user productivity, operational efficiency, and strategic AI investments. As you evolve toward an AI-first enterprise, consider how agentX might be the missing link—the orchestrator that transforms disparate tools and investments into tangible, transformational outcomes.`,\n  date: \"2025-01-20\",\n  tags: [\"AgentX\", \"AI\", \"ROI\", \"EnterpriseAI\"],\n  readTime: \"7 min read\"\n}, {\n  id: 9,\n  title: \"The Future of Operational Efficiency with agentX\",\n  excerpt: \"How agentX improves operational efficiency across the enterprise ecosystem.\",\n  content: `In my earlier post, we explored about the ‘The AI aXis’ in Realizing the Full Potential of Generative AI with agentX. In this blog, let’s dive deeper into how agentX improves operational efficiency across the enterprise ecosystem.\n\nA Journey Through Application Evolution\nOver the past three decades, enterprise applications have evolved from mainframes to client-server models and now Web 3.0. While these shifts have made applications scalable, reliable, and accessible, the way users interact with them has largely remained unchanged.\n\nTo put things into perspective: enterprise applications are still like manual cars, sometimes, requiring significant effort and expertise to operate. But today's world demands modern cars, or in the IT world, intelligent systems that work with minimal input, saving time and effort. And yes, if it's not obvious from my earlier posts... I do love cars 🙂\n\nDespite major technological advancements, many processes remain siloed and manual, creating unnecessary bottlenecks. Users still navigate multiple interfaces, undergo training for new tools, and switch between applications to complete simple tasks. This is where agentX, particularly agentAssistX, steps in to effectively address these challenges.\n\nThe Role of agentAssistX in Streamlining Workflows\nagentAssistX, the first solution in the agentX suite, tackles operational inefficiencies by automating workflows, eliminating redundant steps, and providing an intuitive conversational AI experience - no complex navigation required. And no, this is not just another chatbot, but that’s a story for another day.\n\nHow agentAssistX addresses real-world bottlenecks:\n\nSimplifies IT Support: Logging IT issues takes about 5-7 minutes, navigating through categories in complex ticketing systems. With agentAssistX, a simple conversational text or voice command like \"Log a ticket for laptop connectivity issues\" handles categorization, routing, and priority assignment in seconds. This reduces ticket resolution times by 50%-75%, optimizing IT support processes.\nApproves Processes Effortlessly: Travel booking or initiating budget approvals often requires switching between applications, which causes unnecessary delay. agentAssistX consolidates these steps. A command such as \"Book a flight to SFO and a meeting room at HQ\" handles bookings and sends approval requests to managers through an integrated chat. This reduces the approval cycle from hours or days to minutes.\nOrchestrates Unified Workflows: Enterprise users frequently juggle tools like Salesforce, Jira, or SAP. agentAssistX integrates seamlessly across these platforms, much like a car's autonomous driving system, which combines GPS, lane assist, and adaptive cruise control for a cohesive driving experience. For example, a user can ask, \"What's the status of Project Rainbow2?\" and agentAssistX will automatically retrieve consolidated data from all relevant systems, without any manual effort across multiple systems.\n\nagentAssistX - Everyday AI for Enterprise Applications\nagentAssistX offers possibilities where enterprise applications no longer operate in silos but function as a unified, intelligent ecosystem.\n\nWhat the future looks like:\n\nConversational Interfaces as the Norm: As modern cars rely on voice commands and touchscreens, enterprise tools will shift from graphic user interfaces (GUIs) to conversational user interfaces (CUIs). Users will engage through text, voice, and even gestures, making interactions more intuitive. No menus, no screens, no clicks, no confusion, just ask and get the outcomes.\nIntent-Driven UX: Applications will understand user intent and adjust workflows automatically. For example, if a sales team member asks for \"Pipeline reports by region\", the system generates a customized PowerPoint containing charts commentary and embedded Excel data – all without specifying any tools or using any specific tool. Any change in the Excel data or the charts automatically updates the PowerPoint and the associated commentary with insights.\nEliminating Siloed Applications: AI agents inside agentAssistX will become the single interface for enterprise tools, integrating applications, and ensuring seamless data flow. No Backends, or rather let’s call it, the collapsing of multiple backends.\n\nMeasuring Operational Efficiency Impact with agentAssistX\nHere are the measurable impacts of using agentAssistX:\n\nTime-Saving: Routine tasks, such as process approvals, filling forms, and navigation, take seconds instead of minutes, saving 5–10 weekly hours per employee. This is equivalent to a $25–50M annual saving for 10,000+ employees.\nFaster Decisions: Decision turnaround times improve by 30–50%, saving millions in delays and improving the decision-making process. agentAssistX removes unnecessary manual actions (like filling out forms, categorizing tickets, or clicking around the UX with an intent), allowing decision-makers to focus on core tasks rather than administrative overhead, which speeds up the overall process.\nStreamlined Training: Through conversational UI, onboarding and training times drop by 50–70%, cutting training costs by $500K–700K annually per 1,000 hires. No more learning about nuances of various applications, now employees can interact naturally through text or voice. A command like \"Log an IT ticket for a connectivity issue\" requires no prior knowledge of the underlying system. Any change in business processes or tools does not require any training about the change.\nImproved Employee Experience: Response times shrink from hours to minutes, boosting employee satisfaction and reducing churn.\n\nFor a $10 billion company, these efficiencies could create $1.5–3 billion (up to 30%) in annual value.\n\nagentAssistX is a comprehensive enterprise solution with streamlined workflows that eliminate inefficiencies from business processes, ensuring smooth operations. Enhanced collaboration integrates data and workflows across departments, breaking down silos and improving teamwork. Faster decision-making is achieved as AI provides actionable insights, speeding up decision-making. Simplified user experiences allow users to interact with their conversational AI platform naturally, reducing the need for extensive training.\n\nThe Conversational Engine Behind agentAssistX\nNow something for nerds 😊, agentAssistX integrates enterprise LLMs and app-specific SLMs into workflows, delivering impactful outcomes. If we consider the car analogy, then:\n\nLLMs or SLMs trained on enterprise or application data are the car's engine, providing raw power and intelligence.\nAI Agents are the steering and transmission, translating user inputs into action.\nCUIs are the steering wheel, where users seamlessly interact with the system via text, voice, or visual prompts.\n\nAt Tech Mahindra, we have already integrated conversational AI platforms like Copilot into our internal help desk. With conversational inputs, tasks like ticket creation, which once took 5–7 minutes, now take seconds, similar to using voice commands in a modern car.\n\nPreconditions for Success\nTo fully leverage conversational AI with agentAssistX, enterprises must address key considerations:\n\nTrust and Security (Airbags): AI must securely handle sensitive operations, like airbags protecting passengers.\nData Privacy (Anti-Theft Systems): Balancing convenience with compliance to protect sensitive information.\nHuman Oversight (Driver Monitoring): Maintaining user control, much like self-driving cars, requires human supervision for safety.`,\n  date: \"2025-01-18\",\n  tags: [\"AgentX\", \"OperationalEfficiency\", \"AI\", \"EnterpriseAI\"],\n  readTime: \"6 min read\"\n}];","map":{"version":3,"names":["blogPosts","id","title","excerpt","content","date","tags","readTime"],"sources":["/Users/anushkarawat/blog/src/data/blogPosts.js"],"sourcesContent":["export const blogPosts = [\n  {\n    id: 1,\n    title: \"The DRIVE to Enterprise AI: Architecting the Ecosystem, Not Just the Tools\",\n    excerpt: \"In one of my blogs, I talked about AI aXis, a framework for aligning people, processes, and tools  to create a structured foundation for AI adoption. That premise still holds good and is even more relevant now. Most enterprises are still tinkering with point AI tools, burning their budgets through POCs, and missing the bigger picture - an AI ecosystem that works as one. Because AI isn’t a magic wand.\",\n    content: ` \n    \nReality check (McKinsey Global AI Survey 2024):\n~57 % of companies have adopted AI in at least one function, with $33.9B invested\n≈ $27 B in private-market funding flowed into AI start-ups, just a slice of overall enterprise AI spend\nEarly pilots typically deliver single-digit cost reductions and < 5 % revenue lift\n\nSo where is the gap? Many still treat AI as plug-and-play, when it's really a capability that needs to be architected, embedded, and operationalized across the enterprise.\n\nThe First-Principles Disconnect\nLet's break it down: In one of my posts, I mentioned about thinking from first principles. Truth: AI is a tool, not a strategy; Faulty assumption: merely deploying it will deliver value; Fix: Start with how work actually gets done, and then build layer-by-layer with AI intent. I unpacked some of the first principles, as a foundation base and not optimization layer. \n\nThe WSJ said it best: true ROI shows up when you break the enterprise into atomic tasks. AI isn't about more tools, it's about orchestrating workflows with purpose.\n\nSo, how do CIOs take that atomic thinking and use it to redesign their future proof enterprise AI ecosystem?\n\nThe CIO's Shift: From Control to Enablement\nThe era of central gatekeeping is behind us, no more app builders or system-of-record custodians. Today's CIO or CAO (Chief AI Officer) must shift from tech controller to AI ecosystem creator. That means two fundamental moves:\n\nDemocratize AI, no monopolies, no control towers\nGround strategy in the enterprise, not in vendor roadmaps\n\nCIOs don't need to own every use case. They need empower subject-matter experts and business owners to embed AI into their own workflows. They know where the friction is and where the leverage lies. Enable them with an AI ecosystem to experiment, build, and scale their intent.\n\nThe CIO's role? Build the foundation blocks. Provide the tools. Set the guardrails.\n\nWhat Does a True Enterprise AI Ecosystem Look Like?\nAn enterprise-grade AI strategy can't be a collection of experiments or use cases. It must behave like an operating system for intelligence - layered, coherent, and scalable.\n\nI call it the DRIVE Stack (for easy recall 😊) - five layers that bring together the Infrastructure (Data & Compute), Intelligence (Models & Tools), and Interface (Agents & Experiences). Together, they democratize AI and make it enterprise-grade.\n\nArticle content\nThe D-R-I-V-E to Enterprise AI\nThe D-R-I-V-E Stack breaks down the AI ecosystem into five scalable layers from infrastructure to interface.\n\nArticle content\nD-R-I-V-E Stack\n1. Common Compute Hub – the utility grid\n\nEvery AI workload starts with compute. Enterprises need a shared accelerator backbone (GPUs or ASICs) that teams can access without friction—provisioned instantly, governed invisibly, and tracked in real time, much like spinning up virtual machines (VMs) monitored through FinOps for AI to manage cost. Make compute seamless, and AI experimentation will take off.\n\n2. Curated Data Hub – the raw material\n\nGreat compute is of no use without trusted datasets. CIOs should build an internal data hub like data.gov for the enterprise, where teams can access, preview, and use validated datasets. Ownership, versioning, and quality checks turn data into building blocks—and minimize hallucination, bias, or drift.\n\n3. Foundation Model Engine – the intelligence layer\n\nPre‑trained LLMs / SLMs and vision models—fine‑tuned on enterprise and industry context—should be productized behind secure endpoints. Offer both horizontal models (general reasoning, code, images) and vertical packs (claims adjudication, demand forecasting, employee policy). Provide simple configuration controls and clear performance metrics so teams can optimize without reinventing the wheel.\n\n4. Tooling Workbench – the enterprise workbench\n\nIf foundation models are the brains, the Tooling Workbench is the muscle that turns insight into outcomes. This layer equips business teams with a suite of tools—no heavy coding needed—to stitch AI into day-to-day workflows.\n\nIt includes pre-built connectors to core systems like ERP, CRM, and HR platforms.\nWorkflow engines automate routine tasks—think approvals, escalations, and validations.\nSecure data bridges let insights from AI models flow directly into the applications where decisions are made.\n\nThis enables teams to assemble solutions—not code them from scratch. Whether it's building a seamless customer onboarding journey or generating marketing campaigns on demand, teams can mix and match blocks to create end-to-end flows. Every step is traceable, governed, and auditable—so innovation doesn't come at the cost of control.\n\n5. Agent Marketplace – the end-user experience\n\nAt the top: AI agents that work like apps. Sales copilots, procurement bots, support responders—each powered by the stack beneath. And when business needs something new? They can compose their own using reusable through DRIVE building blocks—often with central validation in sensitive domains like banking and healthcare.\n\nApplication mindset: Together, these layers don't just power AI workflows—they enable a new generation of AI-native apps, composed from building blocks rather than coded from scratch. modern apps = agents + workflows\n\nWhen these five layers lock in, AI stops being a POC lab project. It becomes a repeatable platform that scales across the business. Early adopters like Walmart and DBS Bank are already proving what's possible when you go all in. \n\nFrom Hype to Highways: Rethinking the CIO's Role\nCIOs have spent years fighting tool sprawl. The game has changed now. It's no longer about provisioning another SaaS license—it's about engineering an enterprise-wide intelligence grid.\n\nPicture D-R-I-V-E as a national highway system for insight:\n\nCommon Compute Hub is the asphalt—smooth lanes so every team can move without bottlenecks\nData Hub + Intelligence Engine are the vehicles and fuel—moving insight to where it's needed\nTooling Workbench is the interchange—on-ramps, exits, and merges for insight to flow into work\nGuardrails are the traffic laws—speed limits and checks to ensure safety and trust\nAgent Marketplace is the commerce zone—plug-and-play copilots or custom AI agents on demand. They're the commerce that alongside highways—readymade stops for teams to pull over and use, or small custom shops that for special needs.\n\nThe AI Superhighway doesn't deliver value just by existing. It delivers when the business builds on top—faster decisions, smarter workflows, and new digital products.\n\nMandate for the Modern Day CIO\nForget chasing the next flashy tool. The real mandate is to architect the AI ecosystem, guided by the AI aXis to align people, processes, and tools, and powered by the DRIVE Stack to operationalize intelligence at scale.\n\nBuild, maintain, and keep widening the AI Superhighway so every function - sales, finance, supply chain, HR—can experiment, build, and scale with confidence.\n\nBecause AI isn't a point upgrade. It's the infrastructure of the future—and the AI ecosystem you lay down today will decide how fast and far the business can go tomorrow.`,\n    date: \"2025-13-06\",\n    tags: [\"EnterpriseAI\", \"DRIVEStack\", \"AIStrategy\", \"TechLeadership\"],\n    readTime: \"5 min read\"\n  },\n  {\n    id: 2,\n    title: \"The AI aXis: Realizing the Full Potential of Generative AI with agentX\",\n    excerpt: \"As artificial intelligence (AI) continues to reshape industries, businesses are at a critical juncture. Yet, realizing its full potential requires more than just implementing AI—it demands a strategic ecosystem that aligns people, processes, and tools.\",\n    content: ` As artificial intelligence (AI) continues to reshape industries, businesses are at a critical juncture. Yet, realizing its full potential requires more than just implementing AI—it demands a strategic ecosystem that aligns people, processes, and tools. In my previous post, I highlighted the promise of Tech Mahindra's agentX, which enhances user productivity by automating repetitive tasks and achieving productivity gains of up to 70% (AI Magazine, 2024). Today, we will take a closer look at how businesses can harness the promise of agentX by exploring the necessary ecosystem for its success.\n\nGenerative AI (GenAI) is more than a tool or a technology; instead, it is a transformative force that could revolutionize industries and unlock untapped opportunities. However, the true power of GenAI lies not in the technology itself but in the broader ecosystem, supported by three critical levers: people, processes, and tools. Together, these elements form the AI aXis.\n\nBefore we explore the components of the AI aXis, let's consider an analogy. Imagine you purchased a Ferrari, a car that promises to accelerate from 0 to 60 mph in under five seconds. Exciting, right? But what happens if the driver is only trained to drive a Fiat, and the road is riddled with potholes? Can Ferrari still deliver on its promise? Likely not. GenAI is your Ferrari—a powerful tool with extraordinary potential. But to unlock its capabilities, you need to focus on the three critical elements of the AI aXis: the driver (people), the road (processes), and the engine (tools). Each of these elements is indispensable. Without skilled drivers, smooth roads, and a powerful engine, even a Ferrari won't perform. The same holds true for GenAI—its success relies on aligning people, processes, and tools to achieve seamless integration and transformative outcomes. This is where agentX, Tech Mahindra's GenAI-powered suite, steps in as a key enabler of the AI aXis. \n\nThe Role of An AI Blueprint: The Foundation of Transformation\nBefore embarking on their GenAI journey, organizations need a clear AI blueprint—a comprehensive roadmap that guides every step of the transformation. This blueprint helps to ensure that all AI initiatives are aligned and working toward the same strategic objectives. Without a robust AI blueprint, organizations risk fragmented efforts, where isolated AI projects lack the cohesion to deliver meaningful results.\n\nAn AI blueprint is not static; it should evolve over time and must be updated regularly to reflect changing business priorities. It defines the organization's AI strategy, focus areas, and alignment with long-term goals. It also lays the foundation for how people, processes, and tools will work together to create a cohesive and efficient AI aXis. Many organizations experiment with isolated AI tools or implement solutions without a proper blueprint, which can lead to a lack of meaningful and sustainable outcomes.\n\nPeople: The Driver of the AI aXis\nNo matter how advanced the technology is, its potential remains untapped without a workforce that can use it effectively. People are the drivers of GenAI and must be equipped with the skills, mindset, and confidence to work alongside AI systems effectively.\n\nLeadership is crucial in driving this transformation. By prioritizing upskilling and reskilling, businesses can ensure their workforce is equipped to engage with AI tools, interpret insights, and collaborate seamlessly with these systems. Beyond technical training, there needs to be a cultural shift where employees view AI as a valuable enabler. A well-trained and confident workforce is the cornerstone of the AI aXis, ensuring that GenAI delivers its full potential.\n\nBusiness Processes: Paving the Road for Transformation\nMany organizations make the mistake of embedding AI into existing workflows without reimagining them. This strategy is similar to patching potholes instead of building a new road.\n\nTo fully unlock AI's potential, business processes must be redesigned from the ground up to align with AI capabilities and organizational goals. Additionally, these business processes must be agile enough to adapt to the rapid evolution of AI technologies. Establishing cross-functional workflows is necessary to eliminate silos and enable seamless collaboration. Organizations must reimagine business processes and embrace agility to drive efficiency and innovation at scale. \n\nTools: Building the AI Engine\nLegacy tools, built for pre-AI environments, often need more scalability and flexibility to meet today's demands. This is where 'AI-first tools' come in. These are tools specifically designed for AI environments, with features that enable scalability, adaptability, and seamless integration. To unlock the full potential of GenAI, organizations must invest in these tools. Think of these tools as the engine of the Ferrari. Without a powerful, purpose-built engine, even the smoothest road and the most skilled driver will struggle to deliver results. AI-first tools provide the foundation for automating processes, extracting insights, and scaling innovation across the enterprise. While the AI aXis framework—comprising people, processes, and tools—is essential for GenAI's success, organizations must address foundational challenges to unlock its full potential. These include ensuring data readiness, as high-quality, well-governed data is vital for AI systems. It also involves addressing ethical concerns such as bias, transparency, and privacy, alongside managing resistance to change through effective adoption strategies. Acknowledging and addressing these challenges is key to creating a sustainable AI ecosystem that delivers meaningful results.\n\nAligning the AI aXis with agentX\nWhen the three elements of the AI aXis—people, processes, and tools—are aligned, the full potential of GenAI can be realized. They transform GenAI from merely a high-performance vehicle on a rough road with an untrained driver into a powerful machine that achieves outstanding results. People provide the creativity and competence to engage with AI effectively. Processes create the structure and efficiency to maximize AI's impact. Tools deliver the power and scalability to turn vision into results. Together, these elements form a unified AI aXis that drives success.\n\nThis is where agentX plays a pivotal role. As a GenAI-powered suite, agentX is designed to align the AI aXis and address the challenges organizations face. It transforms how people, processes, and tools work together, providing the foundational AI blueprint and enabling seamless adoption of GenAI. For example, agentX can automate patient scheduling, allowing medical staff to focus on patient care. In the finance sector, it can automate routine data analysis tasks, freeing up analysts to focus on strategic decision-making. For manufacturing, it can optimize supply chain management, reducing costs and improving efficiency. These examples illustrate how agentX can be customized to meet the specific needs of various industries.\n\nagentX also offers a robust 'AI starter pack for organizations.' This pack includes a foundational AI blueprint that guides organizations through every step of their AI transformation and strong organizational change management practices that help businesses effectively drive transformation, navigate challenges, and deliver sustainable outcomes. It's like having a comprehensive guide and a support system to ensure your AI journey is successful.\n\nRealizing the Full Potential of GenAI\nOrganizations must take a proactive and integrated approach to unlock GenAI's promise. Businesses can create a sustainable AI ecosystem by developing a clear AI blueprint, aligning AI aXis, and addressing challenges like data readiness and ethical considerations. Solutions like agentX provide the tools and strategies to bridge gaps, empower teams, and reimagine workflows.\n\nGenAI's potential lies not just in the technology itself but in its surrounding ecosystem. With agentX, organizations have the ultimate toolkit to deliver on GenAI's promise and drive unprecedented outcomes. It's not only about having a high-performance vehicle—it's also about training the driver, paving the road, and building the engine. With agentX, the journey to transformation becomes seamless, impactful, and future-ready.`,\n    date: \"2025-01-06\",\n    tags: [\"AgentX\", \"EnterpriseAutomation\", \"AITransformation\", \"TechMahindra\"],\n    readTime: \"6 min read\"\n  },\n  {\n    id: 3,\n    title: \"Next-Gen BSS for Digital Economy\",\n    excerpt: \"BSS is an integral part of any CSP to handle product, order, revenue, and customer management.\",\n    content: `\n    BSS is an integral part of any CSP to handle product, order, revenue, and customer management. With ~2% of the total spend, many CSPs view BSS as a cost center with a perpetual push to drive down the cost. Historically, CSPs have been through the cycles of buying “Best of the Breed” solutions put together by SI’s to buying out of the box “Best of the Suite” offering end-to-end solutions. But neither come close to meet CSP’s requirements in a nimble, agile, cost-effective manner with vendor neutrality. These transformation projects have a high cost overrun; hence CSP’s hesitation in undertaking these projects does not surprise, thereby letting them continue with highly customized and hard to retire legacy systems. On the other hand, with flat BSS spend (in line with CSP revenues), key suppliers are reconsidering their commitment as they do not consider BSS as an attractive market.   \n\nWhile CSP’s struggle with the BSS technology debt, modern-day players like Netflix use simple pricing models and systems to support their business. The CSP’s may view BSS as an overhead, but new-age players like Netflix have invested in customer experience, personalization, and building data-led BSS systems that anticipate the kind of service customers would want, thereby allowing them to cross-sell / up-sell. CSP’s are attempting to transition to next-gen BSS at par with Netflix’s world but are struggling to do so. They have limited experience building a modular, configurable architecture that reduces the need for customization and support. Notwithstanding the dilemma, there is a realization amongst CSPs that next-gen BSS can expedite their growth through better customer experience and loyalty.  \n\nLooking at some of the critical aspects, next-gen BSS systems would need to have a cloud-native architecture (built ground up to work on cloud as against being cloud-ready or lift & shift) providing scale and flexibility required to support the modular requirements of CSP’s, minimal levels of customization and seamless integration with other ecosystem partners offering SAAS. The on-demand delivery model changes CSP’s commercial terms to business outcomes rather than getting billed for HW & SW. With increased digitization, next-gen BSS would need to go beyond the core services of voice, data, etc., and seamlessly support cross sectors loyalty schemes like loans, credit cards, etc., in summary offering the whole lifestyle experience. Building a solid Partner ecosystem is an essential capability of next-gen BSS as it will enable CSPs to thrive and succeed in the new age digital economy. Partners across the industry must engage with CSPs that offer them the flexibility to verticalize the CSP services along with partner IP. This model has been successfully emulated by Hyperscaler’s, allowing partners to build solutions, effectively letting them cobrand their solutions, define their pricing, hold direct customer relationships with the ability to co-sell and resell. Partners can utilize the underlying marketing, billing platform and divide the revenue/earn incentives. Next-gen BSS would need to support new forms of payments, i.e., customers should be able to transact and pay for services beyond EFT/credit cards like Apple Pay, Venmo, Loyalty points, Bitcoins. Another essential aspect would next-gen BSS is to support dynamic pricing, promotions & bundling of services for greater customer satisfaction, loyalty, and revenues. Spikes in usage often lead to service degradation and eventually customer dissatisfaction. Rather than constraining customers for the bandwidth, they signed up for, liquid Infrastructure based BSS networks can behave intelligently, allowing dynamic changes to the bandwidth (Bandwidth on Demand).  \n\nSome of these characteristics will provide CSP’s agility and flexibility to serve their customers and scale the business. It is time for CSPs to move from a static, labor-intensive legacy BSS system to a next-gen BSS system that intelligently adapts to meet the growing digital demands of their customers built on the ethos of ‘Customer Experience Loyalty.’ `,\n    date: \"2021-05-12\",\n    tags: [\"CIOLeadership\", \"AIEcosystem\", \"DigitalTransformation\", \"TechStrategy\"],\n    readTime: \"3 min read\"\n  },\n  {\n    id: 4,\n    title: \"Putting together the Ecosystem for Open RAN\",\n    excerpt: \"There are many choices for the operators to pick from the array of solutions needed to build the network. However, in the absence of a single solution provider, the key hurdle they face is blending these components seamlessly, including making them deployment-ready with 'single throat to choke.'\",\n    content: `\nIn the previous write-up, we discussed how system integrators (SI's) are best placed to stitch SW-driven RAN through the ecosystem of partners ranging from radio components to HW partners required for CU, DU, RU to SW providers. This opens many choices for the operators to pick from the array of solutions needed to build the network. However, in the absence of a single solution provider, the key hurdle they face is blending these components seamlessly, including making them deployment-ready with 'single throat to choke.'\n\nOpen RAN Partner Ecosystem\nSI's may be best suited to stitch the RAN components and bring the ecosystem together. However, this job has a high degree of complexity, demands advanced skills and knowledge.\n\nThe article 'Who disaggregated my RAN' details some critical areas that need attention to integrate these components from multiple vendors and make them deployment ready. These include\n\nIntegration demands knowledge of underlying hardware and software environments, industry standards (3GPP, O-RAN, Small Cell Forum, etc.), system architectures, hardware processors, System-on-Chip platforms, etc.\nTesting the network functions and ensuring their collective working requires knowledge of industry-standard tools, automating multiple levels of testing across multi-vendor components for the systems to meet the QoS levels defined by the operator.\nBenchmarking to ensure that RAN solutions perform at par with traditional systems for data rates, latency, and other performance aspects.\nDeployment Readiness for an integrated solution to meet the industry-standard benchmarks and operator-specific norms like operator-specific tests, regulatory compliance for various countries, etc.\nFor the greenfield implementations, these are just some of the capabilities required to put the SW-driven RAN together. While the promise around cost savings and vendor lock-in of the SW-driven RAN / Open RAN may be massive, but they can be surpassed by the potential downsides. Trials are in the early stages and still far away from the carrier-grade scalability that offers reliability, higher workloads, and performance. It is still to be seen how the savings will play out as the operators start integrating SW-driven RAN with the legacy RAN (a whole new paradigm of complexity), which to date have mostly been closed and propriety implementations.\n\nSI's will need to embrace these challenges, as this is one area that they cannot afford to ignore or underinvest. To draw parallels, we have seen the shifts in the IT infrastructure side to Hyper-converged infrastructure, which offers software-defined IT infrastructure virtualizing all the elements of conventional \"hardware-defined\" systems. Similarly, SDN has centralized intelligence and routing through the software layer and virtualizes the underlying hardware. The shift to SW-driven RAN is a foregone conclusion, though it will be some time before it gets industrialized. Even though we may see few years of disillusionment with mixed results, SW-driven RAN will mimic the broader industry transition pattern. It is expected that more than 80% of core wireless network deployments will be virtualized.\n\nAnd it is not the greenfield implementations that SI needs to focus on; the co-existence of SW-driven RAN with legacy RAN is critical given significant investments from the operators. This is another area where SI will need to invest in building capabilities (both organically and inorganically ) that addresses interoperability issues, which means they need to learn the know-how of legacy RAN, not a bright spot for many SI's as the legacy RAN market has been dominated by traditional Telco OEM's. While SI' may have an advantage as the RAN gets more and more software'ized and cloud'ified, it also increases the multiple combinations of HW and SW that need to undergo extensive testing before being put to production. SI's are still in the early stages of building the capability around open RAN, while it may be challenging but not difficult. Perhaps we can draw parallels to how SI's navigated the cloud shift and build their capabilities over the past two decades.\n\nKeen to hear your views around how the journey will play out for SI's and if they will be able to create space for themselves when we are seeing the emergence of new-age SW driven Telco OEMs and willingness from traditional Telco OEMs ' to shift their business model from bundling proprietary HW's & SW's to virtualized SW deployed on the public and private cloud.`,\n    date: \"2021-03-29\",\n    tags: [\"ProductAI\", \"AIIntegration\", \"EnterpriseAI\", \"TechMahindra\"],\n    readTime: \"3 min read\"\n  },\n  {\n    id: 5,\n    title: \"RAN Integration - SI's vs. Telco OEM’s\",\n    excerpt: \"With multiple players coming to play in the Open RAN framework across hardware, software, data center segments, there is a genuine concern building up with the MNO’s around who has the ownership of putting this entire puzzle together with the bottom line on performance reliability while keeping the cost down.\",\n    content: `With multiple players coming to play in the Open RAN framework across hardware, software, data center segments, there is a genuine concern building up with the MNO’s around who has the ownership of putting this entire puzzle together with the bottom line on performance reliability while keeping the cost down. Several models are under exploration where MNO (ex. Vodafone and Rakuten) with in house capabilities and skills have played the SI role in stitching up the entire stack together for their pilot projects, while in other cases, the hardware provider is playing the SI role (Dish expects Fujitsu to provide support for radio and antenna integration)      \n\nIt will be hard for a hardware vendor or a 100-year-old MNO to invest and build these capabilities. With more RAN components getting developed and delivered through cloud-native containerized service, there is an increasing possibility of offering RAN-as-service on the near horizon. These new hybrid cloud-based deployment models would need software-centric capabilities and approaches, which a typical MNO or a hardware vendor would find hard to bring in. Integration of Open RAN for a software-centric world would mean software connecting with to all physical components, at all times, to deliver scalability, innovation which changes the game for how open networks integrate. Integration principles typically applied to traditional RAN cannot be applied to a software-driven one where the SW upgrades will happen over the air rather than tower climb up or through truck rolls.     \n\nSI’s are increasingly becoming active and forging partnerships with the likes of Altiostar, Parallel Wireless to build open RAN blueprints that network providers could use to accelerate the deployment of 4G/ 5G Open RAN solutions on their network. WTT, in partnership with CISCO and Altiostar, is building a blueprint where Cisco will provide its Virtual Infrastructure Manager (CVIM) platform, Ultra Packet Core, and Converged SDN Transport along with Altiostar’s 4G and 5G open RAN software. WTT, along with Alitostar and Cisco, will take this validated blueprint and the fully integrated and tested solution to network operators, which in turn will help them to accelerate the technology decisions, reduce time to market, test and deploy the prebuilt validated Open RAN architecture-based solutions in their network, which otherwise could them up to a year to do design, test and validate. Another leading SI recently was signed up by Three UK, one of the UK's leading mobile network carriers, to help the latter configure its mobile network for its ongoing rollout of 5G services. Some of the SI’s are also building the ‘Next Generation Factory Model’ where the facilities offer on-demand labs, conduct proof of concepts, product comparison capable of supporting design, development, and testing for the complex multi-vendor solutions.    \n\nTraditional Telco OEM players like Nokia, Ericsson who have played across HW and SW (though proprietary), may not work well in the Open RAN environment. SI’s are better positioned to offer impartial and not aligned or associated with a specific hardware or software vendor. They are also integrating and testing the Open RAN SW and COTS HW; in many cases, they use the same set of tools for DevOps, CI/CD, and Automation as used in the web app world considered as a sweet spot of the SI’s. For example, in Peru, Telefónica has relied on a Spanish systems integrator called Everis, building in-house resources for implementing virtualization based on Whitestack for DevOps style with Continuous Development Continuous Integration of the software to enable automation. But that’s where the advantage SI ends; Open RAN implementations are still in the early stages with several pilots underway. Nokia recently announced a partnership with hyperscalers, pairing its radio access network (RAN) technologies for 5G and cloud services from Microsoft Azure, Amazon Web Services (AWS), and Google Cloud. The old horses are now focusing on virtualizing their scale-tested network functions on the cloud, which can be deployed in a distributed manner from centralized to the distributed cloud. Open RAN still has some way to go before it gets into mainstream adoption by the MNO’s for the scale operations, where SI’s could play a dominant role. Telco OEMs' willingness to shift their business model from bundling proprietary HW’s & SW’s to virtualized SW deployed on the public and private cloud gives them an edge and deliver to some of the Open RAN's promises like containing the costs for MNO’s. Keen to hear your thoughts on how Telco OEMs will evolve in the new emerging environment of RAN softwareization and how SI’s will create a market for themselves.   `,\n    date: \"2025-01-24\",\n    tags: [\"StartupAI\", \"EnterpriseSaaS\", \"ProductLeadership\", \"TechFounders\"],\n    readTime: \"4 min read\"\n  },\n  {\n    id: 6,\n    title: \"'Mobile core as-a-service'​ powered by Hyperscalers\",\n     excerpt: \" While the interest is unprecedented, some questions are lingering around technology roadmap and maturity to realize ROI on private 5G networks and the best way to put private 5G networks on their implementation roadmap.\",\n    content: `Earlier, we discussed interest from the enterprises, especially the manufacturing companies, in deploying private 5G networks. While the interest is unprecedented, some questions are lingering around technology roadmap and maturity to realize ROI on private 5G networks and the best way to put private 5G networks on their implementation roadmap.\n\nThe last few months have seen an action-packed set of events, where wireless software companies from 'leaders' to 'challengers' made news with hyperscalers. New players like Affirmed Network, Metaswitch got acquired by Microsoft, Nokia - Google announced a partnership to develop cloud-native 5G Core. At the same time, Cisco, Altiostar partnered to create blueprints to accelerate 4G/5G deployment. Operators, too, for quite some time have been toying with hyperscalers where Vodafone & Verizon partnered with AWS to explore edge computing opportunities. The industry's unprecedented action is not surprising given the move to 5G commercialization and private networks. While operators are making the bulk of the investments in building the 5G infrastructure, hyperscalers and wireless software companies are deepening their relationship to run the complex network functions on the hybrid cloud to support a variety of 5G business use cases. \n\n5G fundamentally has different business characteristics from all its predecessors (2G/3G/4G). Previous versions of G's are meant for basic services like Voice / Data / SMS leading to under/over utilization of network resources. For Example, both SMS and end-user playing a game requiring real-time interaction would have access to an equal amount of network resources leading to inefficient utilization of resources for the operators. 5G, with its software-driven approach, gives the ability to design, develop and host 'mobile core' for each type of user/traffic type. For Example, a core could be designed and separated to support messaging (Less bandwidth), or for IoT traffic (secured and streaming), Smart cars, AR / VR (Real-time and high-speed network), etc.\n\nOperators and businesses (for private 5G) require a 'mobile core' that can be deployed and seamlessly managed on the hybrid cloud; support carrier-grade network functions powered by AI, network slicing, etc. - all built with compliance & security first as the underlying principle. With a software-driven approach for 5G, wireless software providers have made extensive use of automation and modern software development principles (DevOps / CICD / Agile lifecycle development). On the other side, Hyperscalers offering compute, storage, analytics, databases, network, machine learning, and several other on-demand services can easily extend their network services to include 5G services like 'mobile core' deployed on hybrid cloud, layered with intelligence, analytics & machine learning. 'Hyperscalers' along with 'wireless software providers' allows businesses to build their private networks in an OPEX model, as it does not necessitate them to procure hardware to host 'mobile core.' With CAPEX out of the window, businesses can now get the fully packaged managed services from 'deployment to operations' for their private networks.\n\n'Mobile core as-a-service' from hyperscalers would offer benefits like fully automated deployments (faster, safer, repeatable), ease of management and orchestration of workloads on hybrid cloud, giving deployment flexibility, automated scaling of network functions for demand-driven network growth, automated fault detection, and correction - reducing manual monitoring and reduced operational complexity. For operators, the additional benefits would include doing away in managing and running the data centers.\n\nPrivate 5G networks for business are an easy target for hyperscalers to offer 'Mobile core as-a-service,' as it allows them to lower the TCO without the hassle of owning up the infrastructure. The question remains, how much operators will adapt and move their core network functions and compute workloads on the cloud. After all, there is a bitter feeling coming out of the 4G era where operators spent billions building the network but lost on monetization to OTT players. While the softwareization of 5G has pushed operators to co-exist with hyperscalers making them frenemies, I am keen to hear your thoughts if operators would eventually adopt services like 'Mobile core as-a-service' from hyperscalers and scale it up for complex 5G use cases.  \n`,\n    date: \"2021-02-16\",\n    tags: [\"CoPilot\", \"GenerativeAI\", \"Innovation\", \"MicrosoftPartner\"],\n    readTime: \"3 min read\"\n  },\n  {\n    id: 7,\n    title: \"Is Private 5G on your Roadmap?\",\n    excerpt: \"We all have been hearing about 5G for some time and its benefits over LTE / Wi-Fi. 5G offers higher reliability, high speed, low latency, making it most suitable for industrial IOT scenarios.\",\n    content: `We all have been hearing about 5G for some time and its benefits over LTE / Wi-Fi. 5G offers higher reliability, high speed, low latency, making it most suitable for industrial IOT scenarios. The excitement over private 5G is understandable, but this is not something new as private LTE networks have been in existence for some time, mostly offered by operators. With 5G, enterprises now have access to unlicensed spectrum (ex. CBRS), allowing them to build a private high-speed network with more bandwidth than the 4G / LTE offered operators. So, it does not surprise us when we see increased interest in private 5G networks from Ford Motors, BMW, BASF, Corning, etc. Off late, the German industrial companies have taken the lead and applied in dozens for licenses to operate their own 5G networks.\n\nIt is not just the manufacturing companies; the spike in interest for private 5G networks is across the industry. To work efficiently, industrial IoT, smart cities, campus networks, modern healthcare, smart manufacturing, intelligent facilities, logistics, and several others need to automate and make sense of their surroundings through robots, intelligent sensors, etc., A low latency network like 5G allows them to remain interconnected and communicate with other devices, enabling them for real-time decisions. While there is a broad consensus on the need and benefits of private networks, the dilemma organizations often face working with traditional operators who know how to design, build, monitor & manage the network vs building their own private 5G network along with a handful of chosen partners (Across OEM's, SW providers etc.).\n\nThanks to the softwarization of networks, cloud, and IoT, we have seen the emergence of new players who have built capabilities in designing, building, and operating private networks. Traditionally, the hardware and software needed to connect the cell sites and run 5G networks come from Huawei, Erickson, Nokia, etc. These proprietary and purpose-built hardware do not offer any decoupling with the software. In Feb 2019, Facebook open sourced Magma, a software platform that helps operators deploy mobile networks quickly and easily, offering software-centric mobile packet core and tools to automate the network management and deployment. Since then, many companies like FreedomFI provide their version of the open-source Magma to the customers, which can be run-on general-purpose hardware. With the software that can run-on general-purpose hardware and spectrum available (outside the control of network operators), enterprises can build their private high-speed network at a significantly lower cost. With private 5G networks, the organization owns the wireless spectrum for the network, network base stations, and other infrastructure. This provides them full control over the network while strengthening cybersecurity, isolating users from the operator's network, and several other benefits.\n\n5g is impacting the present and only going to accelerate its adoption within the organizations. Some may think that this implementation will leave a hole in the enterprise pocket, but that not the case. By some estimates, the private 5G networks can reduce the infrastructure TCO by up to 75%. One such example is where the automated process of crane lifting a container from a remote center gave 70% savings in labor cost at the shipping port.\n\nWhile the benefits of the private 5G networks are unprecedented, there are some questions organizations have in their mind - 1) Given the ongoing softwarization of networks, has technology matured for them to realize ROI on private 5G networks 2) What's the best way to put private 5G networks on implementation roadmap (engage with traditional operator's vs. with the new age partners or any other model).\n\nLet me know your thoughts or if you would like a discussion to demystify this further.`,\n    date: \"2021-01-21\",\n    tags: [\"BSS\", \"Telecom\", \"DigitalTransformation\", \"CloudNative\"],\n    readTime: \"3 min read\"\n  }, \n  {\n    id: 8,\n    title: \"Maximizing ROI with agentX: The Final Dimension\",\n    excerpt: \"In the previous blogs, we have delved into two aspects of the agentX Triple Advantage — peeling the layers that make TechM agentX transformative and what lies beneath the surface.\",\n    content: `In the previous blogs, we have delved into two aspects of the agentX \"Triple Advantage\" — peeling the layers that make TechM agentX transformative and what lies beneath the surface.\n\nFirst, in \"The AI aXis,\" we discussed how agentX brings forth the ecosystem necessary for enterprises to embrace Gen AI, which could potentially help increase productivity by upwards of 70%.\nSecond, agentX enables operational efficiency in the enterprise ecosystem by simplifying workflows and discarding unnecessary layers of complexity.\n\nThird and most importantly, agentX enables enterprises to achieve maximum ROI from AI investments. By leveraging existing investments and assets to uncover untapped opportunities and scale operations, agentX delivers real value and brings enterprises closer to the breakthrough results they've been chasing. In this post, we'll examine how agentX fulfills the last piece of its \"Triple Advantage” and why this dimension may be the missing link in your enterprise AI strategy, a vital step towards becoming an AI-first organization.\n\nThe Challenge of AI Sprawl\nThere are already many AI tools in the market clamoring for attention. Each targets a particular role or task, be it content creation, design, development, or knowledge work. While these tools boost individual productivity, the bigger question remains: How do we combine all these AI tools to elevate enterprise-wide productivity?\n\nAdding another wave of AI tools on top of the many enterprise applications that CIOs are already fighting is daunting, especially when security, compliance, and compatibility issues are factored in. While the workforce is eager to explore the latest AI tools, this constant influx only complicates compatibility, security, and compliance issues. It's common for users to cobble together several tools to accomplish a single task; for instance, they might use something like Copilot for brainstorming and generating content and Napkin AI for images, switching back and forth between various tools to get a job done (note: no endorsement implied here).\n\nSecondly, companies have already made significant investments in automation. New AI capabilities must build on these existing foundations rather than duplicating prior investments.\n\nagentX as the AI Orchestrator\nEnter agentX, The AI Orchestrator. At first glance, this may sound like one more addition to an already bustling AI landscape of tools. agentX is more than just another AI tool; it brings the whole AI ecosystem under one roof as an \"AI Orchestrator.\" By leveraging existing AI and automation investments, adding intelligent agent capabilities ensures that agentX allows businesses to stitch together disparate AI tools and existing automation into an integrated environment. That's where agentX brings in its AI, Agents, and Automation- another \"Triple Advantage.\"\n\nLet’s understand how agentX combines these to make an AI-first enterprise.\n\nBeyond the Hype – The Road to Practical AI Agents in the Enterprise\nAgents are a hot topic. Your LinkedIn feed is likely filled with posts, discussions, and articles about the rise of autonomous agents—or even an \"army of agents\" on its way as if humans didn't already provide enough competition.\n\nThere's no denying the excitement about AI agents' prospects, but we're still early in the hype cycle. Like any other technology, we'll probably progress from initial excitement to inevitable disillusionment before finally settling into a practical, real-world understanding of what agents can and cannot do. While there's little doubt that agents are coming, the question is whether they're ready to disrupt the enterprise landscape. Let's look at how agents might mature and finally deliver on their promise of autonomy.\n\nThe Journey of GenAI Agents: From Interns to Autonomous Experts\nGenAI-based agents will usher in a new wave of automation in enterprises. This may be controversial and purely a representation of my thoughts, but the journey toward fully autonomous agents will also gradually progress, much like the professional growth that happens with human employees, from intern to expert.\n\nFollowing are four essential maturity levels of GenAI agents, each offering different benefits in the aspect of Autonomy, Efficiency, Adaptability, and Scalability:\n\nArticle content\nEmbracing a Continuous Journey with Agents\nOne thing to remember is that the maturity of an agent is not a \"Day 1\" thing-it's a continuous learning journey that will keep evolving with data, workflows, and tools. Beyond the hype cycle, we will get a better view of how fully autonomous agents, augmented by human oversight, could take a more goal-oriented approach in their actions, further presenting themselves as digital twins of humans powered by LLMs with memory for adaptation and learning in real-time and can be certified with confidence by CIOs to operate with enterprise-grade. That doesn't mean, however, that organizations should stand on the sidelines. The maturity timeline may be extended, especially in training agents to handle edge cases, but now is the time to start experimenting. Find the right use cases early and ramp up agent maturity from intern to autonomous to set a strong foundation for future success that one might call \"Forward Failure.\"\n\nAutomation: The Steppingstone to Cognitive Agents\nWith agents in the spotlight, it's easy to overlook another essential part: automation. At the same time, it may seem like a less glamorous, over-discussed topic, but automation remains central to truly unlocking AI's potential within the enterprise. Let's look at how automation pairs with agents to create a seamless, intelligent workflow—and why you might want to use this \"less glamorous\" automation along with agents to build an AI-first enterprise.\n\nEnterprises have spent significant time, effort, and money on automation in the last couple of decades. Is that all suddenly becoming obsolete because AI agents are showing up? Probably not, at least not for now. Instead, LLMs will enable organizations to take incremental steps on top of the existing automation, inject cognitive capabilities into the workflows, and train the next-generation agents.\n\nAutomation will, in many ways, coexist with agents in the near to middle term, enabling businesses to capitalize on their current systems and substantial investments already made. The probabilistic nature of AI means that trusting agents to deliver perfect results 100% of the time isn't feasible, at least not right away. As these agents mature from \"intern\" status to \"autonomous experts,\" automation will remain the backbone that ensures critical tasks are executed reliably. Over time, we may see automation and agents powered by LLMs converge into a single, fluid ecosystem, but that's still a few stages away from maturity. Until then, a coexistence model lets enterprises embrace AI-driven innovation at a measured pace, preserving business continuity while confidently experimenting with the future of autonomous agents.\n\nAI: The UI Layer of \"Triple Advantage\"\nHaving discussed agents and automation, let's move on to the final layer: the AI layer- or, as we might call it, AI for every UI. Whether text, image, voice, or video, enterprises need to connect a range of AI tools to deliver end-to-end user experiences and business solutions. I discussed this in detail in my previous blog, \"No Clicks, Confusion, Just Conversation.\"\n\nFor instance, consider End-to-End Automation of the SDLC—from requirements gathering to code development, testing, and deployment. Here's how integrating AI tools can streamline the process: GitHub Copilot is the engine at the core, enhancing code quality and performance. It plugs seamlessly into popular tools like VSCode, Jira, and DevOps, creating a cohesive development environment. The approach maximizes ROI by leveraging existing investment in productivity tools with a unified solution, enabling better asset utilization and efficiency.\n\nIn the future, these AI-driven interfaces may blend even more closely with agents—but for now, it's all about the coexistence of AI, Agents, and Automation.\n\nagentX: The Orchestrator & Integrator\nagentX from TechM puts all these together: AI, Agents, and Automation into one cohesive ecosystem. agentX is an \"AI Orchestrator,\" ensuring enterprises leverage existing investments while embracing new AI breakthroughs. Further, this step-by-step modernization aligns the maturity of agents with human oversight and operational workflows.\n\nIt's a transformative approach that merges automation with intelligent decision-making. While traditional automation handles predefined tasks, agentic AI can learn, reason, and adapt in real time, offering greater flexibility. In the long run, this synergy moves organizations closer to a future of truly autonomous operations.\n\nFinal Thoughts\nStay Pragmatic. We're still early in the agent hype cycle, so careful oversight and practical use cases are key.\nBuild on What You Have: Enhance existing AI and automation tools with cognitive and agent-based capabilities rather than replacing them.\nAdopt Gradually: Embrace a \"Forward Failure\" mindset—experiment, learn, and refine.\nLeverage agentX: If you're seeking a solution that orchestrates your entire AI ecosystem, TechM agentX is designed to help unlock the potential of AI, Agents, and Automation together.\n\nTechM agentX enables organizations to maximize ROI by uniting user productivity, operational efficiency, and strategic AI investments. As you evolve toward an AI-first enterprise, consider how agentX might be the missing link—the orchestrator that transforms disparate tools and investments into tangible, transformational outcomes.`,\n    date: \"2025-01-20\",\n    tags: [\"AgentX\", \"AI\", \"ROI\", \"EnterpriseAI\"],\n    readTime: \"7 min read\"\n  }, \n  {\n    id: 9,\n    title: \"The Future of Operational Efficiency with agentX\",\n    excerpt: \"How agentX improves operational efficiency across the enterprise ecosystem.\",\n    content: `In my earlier post, we explored about the ‘The AI aXis’ in Realizing the Full Potential of Generative AI with agentX. In this blog, let’s dive deeper into how agentX improves operational efficiency across the enterprise ecosystem.\n\nA Journey Through Application Evolution\nOver the past three decades, enterprise applications have evolved from mainframes to client-server models and now Web 3.0. While these shifts have made applications scalable, reliable, and accessible, the way users interact with them has largely remained unchanged.\n\nTo put things into perspective: enterprise applications are still like manual cars, sometimes, requiring significant effort and expertise to operate. But today's world demands modern cars, or in the IT world, intelligent systems that work with minimal input, saving time and effort. And yes, if it's not obvious from my earlier posts... I do love cars 🙂\n\nDespite major technological advancements, many processes remain siloed and manual, creating unnecessary bottlenecks. Users still navigate multiple interfaces, undergo training for new tools, and switch between applications to complete simple tasks. This is where agentX, particularly agentAssistX, steps in to effectively address these challenges.\n\nThe Role of agentAssistX in Streamlining Workflows\nagentAssistX, the first solution in the agentX suite, tackles operational inefficiencies by automating workflows, eliminating redundant steps, and providing an intuitive conversational AI experience - no complex navigation required. And no, this is not just another chatbot, but that’s a story for another day.\n\nHow agentAssistX addresses real-world bottlenecks:\n\nSimplifies IT Support: Logging IT issues takes about 5-7 minutes, navigating through categories in complex ticketing systems. With agentAssistX, a simple conversational text or voice command like \"Log a ticket for laptop connectivity issues\" handles categorization, routing, and priority assignment in seconds. This reduces ticket resolution times by 50%-75%, optimizing IT support processes.\nApproves Processes Effortlessly: Travel booking or initiating budget approvals often requires switching between applications, which causes unnecessary delay. agentAssistX consolidates these steps. A command such as \"Book a flight to SFO and a meeting room at HQ\" handles bookings and sends approval requests to managers through an integrated chat. This reduces the approval cycle from hours or days to minutes.\nOrchestrates Unified Workflows: Enterprise users frequently juggle tools like Salesforce, Jira, or SAP. agentAssistX integrates seamlessly across these platforms, much like a car's autonomous driving system, which combines GPS, lane assist, and adaptive cruise control for a cohesive driving experience. For example, a user can ask, \"What's the status of Project Rainbow2?\" and agentAssistX will automatically retrieve consolidated data from all relevant systems, without any manual effort across multiple systems.\n\nagentAssistX - Everyday AI for Enterprise Applications\nagentAssistX offers possibilities where enterprise applications no longer operate in silos but function as a unified, intelligent ecosystem.\n\nWhat the future looks like:\n\nConversational Interfaces as the Norm: As modern cars rely on voice commands and touchscreens, enterprise tools will shift from graphic user interfaces (GUIs) to conversational user interfaces (CUIs). Users will engage through text, voice, and even gestures, making interactions more intuitive. No menus, no screens, no clicks, no confusion, just ask and get the outcomes.\nIntent-Driven UX: Applications will understand user intent and adjust workflows automatically. For example, if a sales team member asks for \"Pipeline reports by region\", the system generates a customized PowerPoint containing charts commentary and embedded Excel data – all without specifying any tools or using any specific tool. Any change in the Excel data or the charts automatically updates the PowerPoint and the associated commentary with insights.\nEliminating Siloed Applications: AI agents inside agentAssistX will become the single interface for enterprise tools, integrating applications, and ensuring seamless data flow. No Backends, or rather let’s call it, the collapsing of multiple backends.\n\nMeasuring Operational Efficiency Impact with agentAssistX\nHere are the measurable impacts of using agentAssistX:\n\nTime-Saving: Routine tasks, such as process approvals, filling forms, and navigation, take seconds instead of minutes, saving 5–10 weekly hours per employee. This is equivalent to a $25–50M annual saving for 10,000+ employees.\nFaster Decisions: Decision turnaround times improve by 30–50%, saving millions in delays and improving the decision-making process. agentAssistX removes unnecessary manual actions (like filling out forms, categorizing tickets, or clicking around the UX with an intent), allowing decision-makers to focus on core tasks rather than administrative overhead, which speeds up the overall process.\nStreamlined Training: Through conversational UI, onboarding and training times drop by 50–70%, cutting training costs by $500K–700K annually per 1,000 hires. No more learning about nuances of various applications, now employees can interact naturally through text or voice. A command like \"Log an IT ticket for a connectivity issue\" requires no prior knowledge of the underlying system. Any change in business processes or tools does not require any training about the change.\nImproved Employee Experience: Response times shrink from hours to minutes, boosting employee satisfaction and reducing churn.\n\nFor a $10 billion company, these efficiencies could create $1.5–3 billion (up to 30%) in annual value.\n\nagentAssistX is a comprehensive enterprise solution with streamlined workflows that eliminate inefficiencies from business processes, ensuring smooth operations. Enhanced collaboration integrates data and workflows across departments, breaking down silos and improving teamwork. Faster decision-making is achieved as AI provides actionable insights, speeding up decision-making. Simplified user experiences allow users to interact with their conversational AI platform naturally, reducing the need for extensive training.\n\nThe Conversational Engine Behind agentAssistX\nNow something for nerds 😊, agentAssistX integrates enterprise LLMs and app-specific SLMs into workflows, delivering impactful outcomes. If we consider the car analogy, then:\n\nLLMs or SLMs trained on enterprise or application data are the car's engine, providing raw power and intelligence.\nAI Agents are the steering and transmission, translating user inputs into action.\nCUIs are the steering wheel, where users seamlessly interact with the system via text, voice, or visual prompts.\n\nAt Tech Mahindra, we have already integrated conversational AI platforms like Copilot into our internal help desk. With conversational inputs, tasks like ticket creation, which once took 5–7 minutes, now take seconds, similar to using voice commands in a modern car.\n\nPreconditions for Success\nTo fully leverage conversational AI with agentAssistX, enterprises must address key considerations:\n\nTrust and Security (Airbags): AI must securely handle sensitive operations, like airbags protecting passengers.\nData Privacy (Anti-Theft Systems): Balancing convenience with compliance to protect sensitive information.\nHuman Oversight (Driver Monitoring): Maintaining user control, much like self-driving cars, requires human supervision for safety.`,\n    date: \"2025-01-18\",\n    tags: [\"AgentX\", \"OperationalEfficiency\", \"AI\", \"EnterpriseAI\"],\n    readTime: \"6 min read\"\n  }\n]; "],"mappings":"AAAA,OAAO,MAAMA,SAAS,GAAG,CACvB;EACEC,EAAE,EAAE,CAAC;EACLC,KAAK,EAAE,4EAA4E;EACnFC,OAAO,EAAE,qZAAqZ;EAC9ZC,OAAO,EAAE;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,2KAA2K;EACvKC,IAAI,EAAE,YAAY;EAClBC,IAAI,EAAE,CAAC,cAAc,EAAE,YAAY,EAAE,YAAY,EAAE,gBAAgB,CAAC;EACpEC,QAAQ,EAAE;AACZ,CAAC,EACD;EACEN,EAAE,EAAE,CAAC;EACLC,KAAK,EAAE,wEAAwE;EAC/EC,OAAO,EAAE,8PAA8P;EACvQC,OAAO,EAAE;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+aAA+a;EAC3aC,IAAI,EAAE,YAAY;EAClBC,IAAI,EAAE,CAAC,QAAQ,EAAE,sBAAsB,EAAE,kBAAkB,EAAE,cAAc,CAAC;EAC5EC,QAAQ,EAAE;AACZ,CAAC,EACD;EACEN,EAAE,EAAE,CAAC;EACLC,KAAK,EAAE,kCAAkC;EACzCC,OAAO,EAAE,gGAAgG;EACzGC,OAAO,EAAE;AACb;AACA;AACA;AACA;AACA;AACA;AACA,uWAAuW;EACnWC,IAAI,EAAE,YAAY;EAClBC,IAAI,EAAE,CAAC,eAAe,EAAE,aAAa,EAAE,uBAAuB,EAAE,cAAc,CAAC;EAC/EC,QAAQ,EAAE;AACZ,CAAC,EACD;EACEN,EAAE,EAAE,CAAC;EACLC,KAAK,EAAE,6CAA6C;EACpDC,OAAO,EAAE,0SAA0S;EACnTC,OAAO,EAAE;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6WAA6W;EACzWC,IAAI,EAAE,YAAY;EAClBC,IAAI,EAAE,CAAC,WAAW,EAAE,eAAe,EAAE,cAAc,EAAE,cAAc,CAAC;EACpEC,QAAQ,EAAE;AACZ,CAAC,EACD;EACEN,EAAE,EAAE,CAAC;EACLC,KAAK,EAAE,wCAAwC;EAC/CC,OAAO,EAAE,wTAAwT;EACjUC,OAAO,EAAE;AACb;AACA;AACA;AACA;AACA;AACA,8zDAA8zD;EAC1zDC,IAAI,EAAE,YAAY;EAClBC,IAAI,EAAE,CAAC,WAAW,EAAE,gBAAgB,EAAE,mBAAmB,EAAE,cAAc,CAAC;EAC1EC,QAAQ,EAAE;AACZ,CAAC,EACD;EACEN,EAAE,EAAE,CAAC;EACLC,KAAK,EAAE,qDAAqD;EAC3DC,OAAO,EAAE,8NAA8N;EACxOC,OAAO,EAAE;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,CAAC;EACGC,IAAI,EAAE,YAAY;EAClBC,IAAI,EAAE,CAAC,SAAS,EAAE,cAAc,EAAE,YAAY,EAAE,kBAAkB,CAAC;EACnEC,QAAQ,EAAE;AACZ,CAAC,EACD;EACEN,EAAE,EAAE,CAAC;EACLC,KAAK,EAAE,gCAAgC;EACvCC,OAAO,EAAE,iMAAiM;EAC1MC,OAAO,EAAE;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uFAAuF;EACnFC,IAAI,EAAE,YAAY;EAClBC,IAAI,EAAE,CAAC,KAAK,EAAE,SAAS,EAAE,uBAAuB,EAAE,aAAa,CAAC;EAChEC,QAAQ,EAAE;AACZ,CAAC,EACD;EACEN,EAAE,EAAE,CAAC;EACLC,KAAK,EAAE,iDAAiD;EACxDC,OAAO,EAAE,qLAAqL;EAC9LC,OAAO,EAAE;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,6UAA6U;EACzUC,IAAI,EAAE,YAAY;EAClBC,IAAI,EAAE,CAAC,QAAQ,EAAE,IAAI,EAAE,KAAK,EAAE,cAAc,CAAC;EAC7CC,QAAQ,EAAE;AACZ,CAAC,EACD;EACEN,EAAE,EAAE,CAAC;EACLC,KAAK,EAAE,kDAAkD;EACzDC,OAAO,EAAE,6EAA6E;EACtFC,OAAO,EAAE;AACb;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mIAAmI;EAC/HC,IAAI,EAAE,YAAY;EAClBC,IAAI,EAAE,CAAC,QAAQ,EAAE,uBAAuB,EAAE,IAAI,EAAE,cAAc,CAAC;EAC/DC,QAAQ,EAAE;AACZ,CAAC,CACF","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}